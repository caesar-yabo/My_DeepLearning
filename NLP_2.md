NLP从入门到不放弃（二）
日期：2019-07-05 10:01浏览：22评论：0
一、文本的表示方法

1.基于词袋模型bag-of-words

```
  忽略单词顺序、语法、句法，对文档中所有词构建n维词典，每个文本都可以用n维向量表示，反应词典中每个单词再文本中出现的频率，无法说明文本中单词顺序。广泛应用在文件分类领域，可以实现基础理解。

  one-hot：独热码、一位有效编码，词的数量决定维度。缺点：维度泛滥，词义鸿沟

  tf-idf：tf进行词频计算，idf对词频进行排序（考虑所有文章后计算关键词的新鲜度），对文章中每个词的tf与idf相乘处理后排序，前几即为关键词。优点：简单快速、容易理解；缺点：无法体现位置信息及上下文的重要性，不能解决分词失误；参考链接：https://zhuanlan.zhihu.com/p/31197209

  TextRank：常用于摘要、关键词短语等文本生成，提取速度慢，不能解决词义问题；参考链接：https://blog.csdn.net/AndrewLee_/article/details/55095538
```

2.主题模型

```
   LSA（SVD）：基于假设--若两个词多次出现在同一文档，则认为具有语义相似性--利用大量的文本构建矩阵，利用SVD进行降维；可以进行浅层语义分析；参考链接：https://blog.csdn.net/u013395878/article/details/51741706

   pLSA：概率隐性语义分析，参考链接：https://www.cnblogs.com/Determined22/p/7237111.html

   LDA：隐狄利克雷分布，参考链接：https://www.cnblogs.com/pinard/p/6831308.html
```

3.基于词向量的固定表征：

```
   Word2Vec、fastText、glove
```

4.基于词向量的动态表征：

```
   elmo、GPT、bert

   我目前需要关注的还是文本相似度这一块，因此主要关注词向量，在学习过程中扫了一眼词袋模型和主题模型。实际这些模型不一定只用于自然语言处理领域，还有可能应用在其他领域，这些陈年的模型在针对一些特定场景的时候依然有无可取代的作用，因此对应这些模型的缺点做出的优化调整也非常多，无法一一列举。又想到初学统计方法的时候老师说的话，还存世的算法一定有其价值，不结合具体场景无法评价算法优劣。

   这个世界有点大啊，不知道实习的这段时间能见识到多少。其实学了这么几天，还不如导师开会五分钟讲的内容翔实。师父就是师父啊，心疼他这么厉害有我这么菜的徒弟。
```

​       
